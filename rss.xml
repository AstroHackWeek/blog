<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Astro Hack Week</title><link>http://astrohackweek.github.io/</link><description>The Astro Hack Week Blog</description><atom:link type="application/rss+xml" rel="self" href="http://astrohackweek.github.io/blog/rss.xml"></atom:link><language>en</language><lastBuildDate>Tue, 06 Oct 2015 04:03:45 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Hack the textbook figures</title><link>http://astrohackweek.github.io/blog/Hack-the-textbook-figures.html</link><dc:creator>Michael Gully-Santiago</dc:creator><description>&lt;div&gt;&lt;p&gt;Every single figure in the &lt;a href="http://press.princeton.edu/titles/10159.html"&gt;text book&lt;/a&gt; &lt;em&gt;Statistics, Data Mining, and Machine Learning in Astronomy&lt;/em&gt; is &lt;a href="http://www.astroml.org/book_figures/"&gt;downloadable and fully reproducible online&lt;/a&gt;.  Jake VanderPlas accomplished this heroic feat as a graduate student at the University of Washington.  Jake recalled the origin story to some of us at the hack week.  He explained that he would usually have the figure done the same week it was conceived, and was really pretty happy with the whole experience of being a part of making the textbook and ultimately becoming a coauthor.  His figures are now indispensable. Because of Jake's investment, generations of astronomers to come can now benefit from reproducing the explanatory material in the Textbook.  The figures are complementary to the textbook prose.  The textbook prose explains the theoretical framework underlying the concepts.  Equations are derived.  But by digging into the textbook figure Python code, the reader can see how the method is &lt;em&gt;implemented&lt;/em&gt;, and try it out by tweaking the input.  "What happens if I double the noise? Or decimate the number of data points?  Or change this-or-that parameter?  How long does it take to run?"  &lt;/p&gt;
&lt;p&gt;These and other questions motivated my hack idea, which was to dig into the source code of textbook figures and do some hacking.  &lt;/p&gt;
&lt;div id="test_figure"&gt;&lt;/div&gt;

&lt;script type="text/javascript" src="http://astrohackweek.github.io/blog/js/hack-book-figs.js"&gt;&lt;/script&gt;

&lt;script&gt;
  draw_figure("test_figure");
&lt;/script&gt;

&lt;p&gt;So on Wednesday of the Hack Week a table of about 8 of us all hacked the book figures.  The figure above is one of those figures, 
&lt;/p&gt;&lt;p&gt;&lt;a href="http://astrohackweek.github.io/blog/Hack-the-textbook-figures.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>hacking</category><category>IPython Notebook</category><category>machine learning</category><category>statistics</category><category>visualization</category><guid>http://astrohackweek.github.io/blog/Hack-the-textbook-figures.html</guid><pubDate>Tue, 07 Oct 2014 15:30:00 GMT</pubDate></item><item><title>Bayesian Evidence Calculation</title><link>http://astrohackweek.github.io/blog/bayesian-evidence.html</link><dc:creator>Kyle Barbary</dc:creator><description>&lt;div&gt;&lt;p&gt;In a Bayesian framework, object classification or model comparison can
be done naturally by comparing the Bayesian &lt;em&gt;evidence&lt;/em&gt; between two or
more models, given the data. The evidence is the integral of the
likelihood of the data over the entire prior volume for all the model
parameters, weighted by the prior. (The ratio of evidence for two
different models is known as the &lt;a href="http://en.wikipedia.org/wiki/Bayes_factor"&gt;Bayes
Factor&lt;/a&gt;.) This
multi-dimensional integral gets increasingly computationally intensive
as the number of parameters increases. As a result, several clever
algorithms have been developed to efficiently approximate the answer.&lt;/p&gt;
&lt;p&gt;In this hack, I looked at a couple specific implementations of such
algorithms in Python.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://astrohackweek.github.io/blog/bayesian-evidence.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian evidence</category><category>hacking</category><guid>http://astrohackweek.github.io/blog/bayesian-evidence.html</guid><pubDate>Fri, 03 Oct 2014 15:00:00 GMT</pubDate></item><item><title>Hacked Ethnographic Fieldnotes</title><link>http://astrohackweek.github.io/blog/ethnographic-notes.html</link><dc:creator>Brittany Fiore-Silfvast</dc:creator><description>&lt;div&gt;&lt;div style="float:left"&gt;
&lt;img src="http://astrohackweek.github.io/blog/images/fiore-silfvast.jpg" width="300px"&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;&lt;a href="http://fioresilfvast.org/"&gt;Brittany Fiore-Silfvast&lt;/a&gt; is a postdoctoral fellow with UW's Moore/Sloan-funded Data Science Environment and works as a data science ethnographer. Her research focuses on the social and organizational dimensions of data-intensive transformations in arenas such as scientific research, healthcare, global development, design and construction, and warfare.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;What is data science ethnography anyway?&lt;/h4&gt;
&lt;p&gt;As an ethnographer of data science, I immerse myself in particular communities to understand how they make sense of the world, how they communicate, what motivates them, and how they work together. I spent a week at astro data hack week, which might as well have been a foreign culture to me. I participated as an active listener, trying to sensitize myself to the culture and discern patterns that may not be self-evident to people within the community. Ethnography can have the effect of making the ordinary strange, such that the norms, objects, and practices that the community takes for granted become fascinating, informative sites for learning and discovery. Many of the astro hackers were probably thinking, "Why is this woman hanging around watching me code on my laptop? There is nothing interesting here." But I assured them it was interesting to me because I was seeing their everyday practice in the context of a complex social and technical world that is in flux.&lt;/p&gt;
&lt;p&gt;Ethnography can be thought of as a form of big data. Typically hundreds of pages of fieldnotes, interview transcripts, and artifacts from the field would be recorded over a long period of time until the ethnographer determines they have reached a point of saturation. The analysis process co-occurs with the data collection, iteratively shaping the focus of the research and observation strategy. Across this massive dataset with an abundance of unwieldy dimensions, the ethnographer has to make sense. &lt;/p&gt;&lt;p&gt;&lt;a href="http://astrohackweek.github.io/blog/ethnographic-notes.html"&gt;Read more…&lt;/a&gt; (9 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>ethnography</category><guid>http://astrohackweek.github.io/blog/ethnographic-notes.html</guid><pubDate>Wed, 01 Oct 2014 19:00:00 GMT</pubDate></item><item><title>Time Series Forecasting with Random Forest</title><link>http://astrohackweek.github.io/blog/time-series-rf.html</link><dc:creator>James Davenport</dc:creator><description>&lt;div&gt;&lt;p&gt;After &lt;a href="http://astro.berkeley.edu/~jbloom/"&gt;Josh Bloom&lt;/a&gt;'s wonderful lecture on &lt;a href="http://en.wikipedia.org/wiki/Random_forest"&gt;Random Forest&lt;/a&gt; regression I was excited to out his &lt;a href="https://github.com/AstroHackWeek/AstroHackWeek2014/tree/master/day4"&gt;example code&lt;/a&gt; on my &lt;em&gt;Kepler&lt;/em&gt; data. Josh explained regression with machine learning as taking many data points with a variety of features/atributes, and using relationships between these features to predict some other parameter. He explained that the Random Forest algorithm works by constructing many decision trees, which are used to construct the final prediction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I wondered: could I use the Random Forest (RF) to do time series forecasting?&lt;/strong&gt; Of course, as &lt;a href="http://astrohackweek.github.io/blog/multi-output-random-forests.html"&gt;Jake noted&lt;/a&gt;, RF only predicts single properties. As a result, RF isn't a good choice for doing trend forecasting over long time periods. (well, maybe) Instead, this would use RF to just predict the &lt;em&gt;next&lt;/em&gt; datapoint.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://astrohackweek.github.io/blog/time-series-rf.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>random forest</category><category>summary</category><category>time series</category><guid>http://astrohackweek.github.io/blog/time-series-rf.html</guid><pubDate>Mon, 29 Sep 2014 15:30:00 GMT</pubDate></item><item><title>K2 Photometry</title><link>http://astrohackweek.github.io/blog/k2-photometry.html</link><dc:creator>Dan Foreman-Mackey</dc:creator><description>&lt;div&gt;&lt;div style="float: left; padding-bottom: 6px;"&gt;
    &lt;img src="http://astrohackweek.github.io/blog/images/dfm-adhw-img.png" width="500"&gt;
&lt;/div&gt;

&lt;p&gt;For my AstroHackWeek project, I decided to hack on the new images coming from
&lt;a href="http://keplerscience.arc.nasa.gov/K2/"&gt;NASA's K2 mission&lt;/a&gt;, the second
generation of the &lt;em&gt;Kepler&lt;/em&gt; satellite.
The original &lt;em&gt;Kepler&lt;/em&gt; mission obtained exquisite precision in the photometry
because the satellite's pointing was stable to better than a hundredth of a
pixel.
For &lt;em&gt;K2&lt;/em&gt;, this is no longer the case.
Therefore, we'll need to work a little harder to extract useful photometric
measurements from these data.
That being said, these pointing variations also break some of the degeneracies
between the flat field of the detector and the PSF so we might be able to
learn some things about &lt;em&gt;Kepler&lt;/em&gt; that we couldn't have with the previous data
releases.&lt;/p&gt;
&lt;p&gt;At the hack week, I got a proof-of-concept implemented but there's definitely
a lot to do if we want to develop a general method.
The basic idea is to build a flexible probabilistic model inspired by what we
know about the physical properties of &lt;em&gt;Kepler&lt;/em&gt; and then optimize the
parameters of this model to produce a light curve.&lt;/p&gt;
&lt;p&gt;The figure at the top of this page shows a single frame observed in the
engineering phase of K2 on the left and, on the right, the optimized model for
the same frame.
The code lives (and is being actively developed) on GitHub
&lt;a href="https://github.com/dfm/kpsf"&gt;dfm/kpsf&lt;/a&gt; and the K2 data can be downloaded from
&lt;a href="http://archive.stsci.edu/search_fields.php?mission=k2"&gt;MAST&lt;/a&gt; using Python and
the git version of &lt;a href="https://github.com/dfm/kplr"&gt;kplr&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://astrohackweek.github.io/blog/k2-photometry.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>hacking</category><category>kepler</category><category>probabilistic models</category><guid>http://astrohackweek.github.io/blog/k2-photometry.html</guid><pubDate>Thu, 25 Sep 2014 18:00:00 GMT</pubDate></item><item><title>Hack Week Responses: Blogs and Twitter</title><link>http://astrohackweek.github.io/blog/hack-week-thoughts-blog-twitter.html</link><dc:creator>Jake VanderPlas</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;img src="http://astrohackweek.github.io/blog/galleries/AstroHackWeek2014/hackweek_panorama.jpg" width="100%"&gt;&lt;/p&gt;
&lt;p&gt;We're still working on getting some hack summaries here on the website. In the mean-time, some of the hack week participants have been blogging and writing about their own thoughts from the week! I wanted to compile a few of these responses here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ruth Angus' post on &lt;a href="http://astrobites.org/2014/09/24/astro-data-hack-week/"&gt;AstroBites&lt;/a&gt;:&lt;/strong&gt; a great high-level summary of what went on through the week! Ruth does a great job capturing the spirit of the event, as well as some details on things she learned and took home.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;David Hogg's daily research posts:&lt;/strong&gt; If you've never come across &lt;a href="http://hoggresearch.blogspot.com/"&gt;Hogg's Research Blog&lt;/a&gt;, it's worth digging around in it for a while. Each day, Hogg writes a brief summary of what he worked on or thought about for the day, and the result is a nearly decade-long log of his scientific ideas and interactions. He did this through the hack week as well, and you can read his thoughts here: &lt;a href="http://hoggresearch.blogspot.com/2014/09/astrodata-hack-week-day-1.html"&gt;Day 1&lt;/a&gt;, &lt;a href="http://hoggresearch.blogspot.com/2014/09/astrodata-hack-week-day-2.html"&gt;Day 2&lt;/a&gt;, &lt;a href="http://hoggresearch.blogspot.com/2014/09/astrodata-hack-week-day-3.html"&gt;Day 3&lt;/a&gt;, &lt;a href="http://hoggresearch.blogspot.com/2014/09/astrodata-hack-week-day-4.html"&gt;Day 4&lt;/a&gt;, &lt;a href="http://hoggresearch.blogspot.com/2014/09/astrodata-hack-week-day-5.html"&gt;Day 5&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adrian Price-Whelan's &lt;a href="http://apwhelan.blogspot.com/2014/09/cell-macros-in-ipython-notebook.html"&gt;IPython Cell Macros&lt;/a&gt; hack:&lt;/strong&gt; so often when starting up an IPython notebook, we find ourselves importing all the same tools in the first cell. Now there's a button which adds this cell automatically!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;UW eScience has a quick &lt;a href="http://escience.washington.edu/blog/astrodata-hack-week-2014"&gt;writeup&lt;/a&gt;:&lt;/strong&gt; drawn mostly from our earlier post here. Great to have recognition from one of our sponsoring organizations!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And of course, there's always Twitter. Many of the week's participants were tweeting with the &lt;a href="https://twitter.com/hashtag/astrohackweek"&gt;#AstroHackWeek&lt;/a&gt; tag. Below are a few randomly-chosen highlights.&lt;/p&gt;
&lt;p&gt;I know that I, for one, am really hoping this happens again.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://astrohackweek.github.io/blog/hack-week-thoughts-blog-twitter.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>blog roll</category><category>summary</category><category>twitter</category><guid>http://astrohackweek.github.io/blog/hack-week-thoughts-blog-twitter.html</guid><pubDate>Wed, 24 Sep 2014 17:00:00 GMT</pubDate></item><item><title>Multi-Output Random Forests</title><link>http://astrohackweek.github.io/blog/multi-output-random-forests.html</link><dc:creator>Jake VanderPlas</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Classic machine learning algorithms map multiple inputs to a single output.
For example, you might have five photometric observations of a galaxy, and predict a single attribute or label (like the redshift, metallicity, etc.)
When multiple ouputs are desired, standard practice is to essentially run two independent classifications: first predict one variable, then the next.
The problem with this approach is that it completely ignores &lt;em&gt;correlations&lt;/em&gt; in the outputs.&lt;/p&gt;
&lt;p&gt;This is my Thursday hack, which was to explore ideas to improve on this within Random Forests.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://astrohackweek.github.io/blog/multi-output-random-forests.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>hacking</category><category>machine learning</category><category>python</category><category>random forests</category><guid>http://astrohackweek.github.io/blog/multi-output-random-forests.html</guid><pubDate>Sat, 20 Sep 2014 18:30:00 GMT</pubDate></item><item><title>Astro Hack Week Wrapup</title><link>http://astrohackweek.github.io/blog/astro-hack-week-wrapup.html</link><dc:creator>Jake VanderPlas</dc:creator><description>&lt;div&gt;&lt;div style="float:left"&gt;
&lt;img src="http://astrohackweek.github.io/blog/images/HackWeek.jpg" width="300px"&gt;
&lt;br&gt;
&lt;small&gt;Photo by &lt;a href="http://instagram.com/p/s_kq-OKS_p/"&gt;Adrian Price-Whelan&lt;/a&gt;&lt;/small&gt;
&lt;/div&gt;

&lt;p&gt;The first &lt;a href="http://astrohackweek.github.io"&gt;Astro Hack Week&lt;/a&gt; took place from September 15-19, 2014 at University of Washington. We had about 45 attendees through the week. We spent the mornings together learning new coding, statistics, and data analysis skills, and spent the afternoons working in pairs and groups on a wide variety of projects. These projects spanned a range of topics, and comprised everything from short exercises to development of teaching materials to full-blown research projects which will likely lead to publications!&lt;/p&gt;
&lt;p&gt;Along with these hacks, the afternoons were also punctuated by informal breakout sessions on everything from using Git to constructing Probabilistic Graphical Models. Thanks to all the participants who stepped up to lead these breakouts and share their expertise with others!&lt;/p&gt;
&lt;p&gt;We've set up this blog to report and record some of the results of the workshop. Over the next few weeks, we hope that everyone who attended will write a short post (or two!) and let us know what they worked on and learned during the week!&lt;/p&gt;
&lt;p&gt;Finally, a &lt;strong&gt;huge&lt;/strong&gt; thanks to our sponsors, the &lt;a href="http://www.moore.org"&gt;Moore Foundation&lt;/a&gt;, the &lt;a href="http://www.sloan.org"&gt;Sloan Foundation&lt;/a&gt;, and the &lt;a href="http://escience.washington.edu"&gt;UW eScience Institute&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Stay tuned, and look for more posts in the coming days and weeks!&lt;/p&gt;&lt;/div&gt;</description><category>summary</category><guid>http://astrohackweek.github.io/blog/astro-hack-week-wrapup.html</guid><pubDate>Sat, 20 Sep 2014 16:00:00 GMT</pubDate></item></channel></rss>